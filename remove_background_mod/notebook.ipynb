{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "from dataset import SingleCellRNACountsDataset\n",
    "from dataprep import prep_sparse_data_for_training as prep_data_for_training\n",
    "from encoder import EncodeZ, CompositeEncoder, EncodeNonZLatents\n",
    "from decoder import Decoder\n",
    "from train import run_training\n",
    "from model import RemoveBackgroundPyroModel\n",
    "import pyro\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, Trace_ELBO\n",
    "import consts as consts\n",
    "from pathlib import Path\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to change here!\n",
    "current_dir = globals()['_dh'][0]\n",
    "# current_dir = Path(__file__).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"full\"\n",
    "fraction_empties = 0.5\n",
    "expected_cell_count = 5_000\n",
    "total_droplet_barcodes = 25_000\n",
    "fpr = 0.01\n",
    "low_count_threshold = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/miniconda3/envs/torch_env2/lib/python3.9/site-packages/anndata/_core/anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    }
   ],
   "source": [
    "adata = sc.read_10x_h5(current_dir / \"..\" / \"example_data\" / \"MS466\" / \"raw_feature_bc_matrix.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'matrix': sp.csr_matrix(adata.X),\n",
    "    'barcodes':np.array(adata.obs_names, dtype=str),\n",
    "    'gene_names': np.array(adata.var_names, dtype=str),\n",
    "    'gene_ids': None,\n",
    "    'feature_types': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimming dataset for inference.\n",
      "Including 36601 genes that have nonzero counts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/Work/CellBenderMod/remove_background_mod/dataset.py:1366: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  empty_log_counts = mode(np.round(np.log1p(counts[counts > cut]),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior on counts in empty droplets is 180\n",
      "Prior on counts for cells is 2763\n",
      "Excluding barcodes with counts below 90\n",
      "Using 5000 probable cell barcodes, plus an additional 20000 barcodes, and 49444 empty droplets.\n",
      "Largest surely-empty droplet has 216.0 UMI counts.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dataset.SingleCellRNACountsDataset at 0x7f95c044d160>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we also compute all the priors\n",
    "dataset_obj = SingleCellRNACountsDataset(\n",
    "    data=data,\n",
    "    model_name=model_type,\n",
    "    low_count_threshold=low_count_threshold,\n",
    "    fpr=fpr,\n",
    "    expected_cell_count=expected_cell_count,\n",
    "    total_droplet_barcodes=total_droplet_barcodes, \n",
    "    fraction_empties=fraction_empties\n",
    ")\n",
    "dataset_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_cells': 5000,\n",
       " 'cell_counts': 2763,\n",
       " 'empty_counts': 180,\n",
       " 'log_counts_crossover': 6.561465608076693,\n",
       " 'd_std': 0.2725937153621734,\n",
       " 'cell_prob': 0.1,\n",
       " 'cell_logit': -2.197224577336219,\n",
       " 'chi_ambient': tensor([1.7276e-07, 2.0595e-14, 2.0595e-14,  ..., 2.0595e-14, 5.7011e-06,\n",
       "         5.1828e-07]),\n",
       " 'chi_bar': tensor([1.7241e-08, 2.0552e-15, 2.0552e-15,  ..., 2.0552e-15, 2.6723e-06,\n",
       "         5.5170e-07])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_obj.priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = dataset_obj.get_count_matrix()\n",
    "# Configure pyro options (skip validations to improve speed).\n",
    "pyro.enable_validation(False)\n",
    "pyro.distributions.enable_validation(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset into DataLoaders.\n",
    "frac = 1  # Fraction of barcodes to use for training\n",
    "batch_size = int(min(300, frac * dataset_obj.analyzed_barcode_inds.size / 2))\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "z_hidden_dims = [100]\n",
    "d_hidden_dims = [10, 2]\n",
    "p_hidden_dims = [100, 10]\n",
    "z_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_empties = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CompositeEncoder' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/philipp/Work/CellBenderMod/remove_background_mod/notebook.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blserver/home/philipp/Work/CellBenderMod/remove_background_mod/notebook.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m encoder_z \u001b[39m=\u001b[39m EncodeZ(input_dim\u001b[39m=\u001b[39mcount_matrix\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blserver/home/philipp/Work/CellBenderMod/remove_background_mod/notebook.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                     hidden_dims\u001b[39m=\u001b[39mz_hidden_dims,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blserver/home/philipp/Work/CellBenderMod/remove_background_mod/notebook.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m                     output_dim\u001b[39m=\u001b[39mz_dim,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blserver/home/philipp/Work/CellBenderMod/remove_background_mod/notebook.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m                     input_transform\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnormalize\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blserver/home/philipp/Work/CellBenderMod/remove_background_mod/notebook.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m encoder_other \u001b[39m=\u001b[39m EncodeNonZLatents(n_genes\u001b[39m=\u001b[39mcount_matrix\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blserver/home/philipp/Work/CellBenderMod/remove_background_mod/notebook.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m                                     z_dim\u001b[39m=\u001b[39mz_dim,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blserver/home/philipp/Work/CellBenderMod/remove_background_mod/notebook.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m                                     hidden_dims\u001b[39m=\u001b[39mconsts\u001b[39m.\u001b[39mENC_HIDDEN_DIMS,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blserver/home/philipp/Work/CellBenderMod/remove_background_mod/notebook.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m                                     log_count_crossover\u001b[39m=\u001b[39mdataset_obj\u001b[39m.\u001b[39mpriors[\u001b[39m'\u001b[39m\u001b[39mlog_counts_crossover\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blserver/home/philipp/Work/CellBenderMod/remove_background_mod/notebook.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m                                     prior_log_cell_counts\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mlog1p(dataset_obj\u001b[39m.\u001b[39mpriors[\u001b[39m'\u001b[39m\u001b[39mcell_counts\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blserver/home/philipp/Work/CellBenderMod/remove_background_mod/notebook.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m                                     input_transform\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnormalize\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Blserver/home/philipp/Work/CellBenderMod/remove_background_mod/notebook.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m encoder \u001b[39m=\u001b[39m CompositeEncoder({\u001b[39m'\u001b[39;49m\u001b[39mz\u001b[39;49m\u001b[39m'\u001b[39;49m: encoder_z,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blserver/home/philipp/Work/CellBenderMod/remove_background_mod/notebook.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m                             \u001b[39m'\u001b[39;49m\u001b[39mother\u001b[39;49m\u001b[39m'\u001b[39;49m: encoder_other})\u001b[39m.\u001b[39;49mto(device)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CompositeEncoder' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# Set up encode\n",
    "encoder_z = EncodeZ(input_dim=count_matrix.shape[1],\n",
    "                    hidden_dims=z_hidden_dims,\n",
    "                    output_dim=z_dim,\n",
    "                    input_transform='normalize')\n",
    "\n",
    "encoder_other = EncodeNonZLatents(n_genes=count_matrix.shape[1],\n",
    "                                    z_dim=z_dim,\n",
    "                                    hidden_dims=consts.ENC_HIDDEN_DIMS,\n",
    "                                    log_count_crossover=dataset_obj.priors['log_counts_crossover'],\n",
    "                                    prior_log_cell_counts=np.log1p(dataset_obj.priors['cell_counts']),\n",
    "                                    input_transform='normalize')\n",
    "\n",
    "encoder = CompositeEncoder({'z': encoder_z,\n",
    "                            'other': encoder_other})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = torch.from_numpy(np.asarray(count_matrix.todense().astype(np.float32))).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/philipp/Work/CellBenderMod/remove_background_mod/notebook.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blserver/home/philipp/Work/CellBenderMod/remove_background_mod/notebook.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m encoder_z\u001b[39m.\u001b[39;49mforward(test_X)\n",
      "File \u001b[0;32m~/Work/CellBenderMod/remove_background_mod/encoder.py:114\u001b[0m, in \u001b[0;36mEncodeZ.forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m x \u001b[39m=\u001b[39m transform_input(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform)\n\u001b[1;32m    113\u001b[0m \u001b[39m# Compute the hidden layers.\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoftplus(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinears[\u001b[39m0\u001b[39;49m](x))\n\u001b[1;32m    115\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinears)):  \u001b[39m# Second hidden layer onward\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoftplus(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinears[i](hidden))\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env2/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env2/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "encoder_z.forward(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setu p decoder\n",
    "decoder = Decoder(input_dim=z_dim,\n",
    "                    hidden_dims=z_hidden_dims[::-1],\n",
    "                    output_dim=count_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the model\n",
    "model = RemoveBackgroundPyroModel(model_type=\"full\",\n",
    "                                  encoder=encoder,\n",
    "                                  decoder=decoder,\n",
    "                                  dataset_obj=dataset_obj,\n",
    "                                  use_cuda=use_cuda)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up train and test loader\n",
    "train_loader, test_loader = \\\n",
    "    prep_data_for_training(dataset=count_matrix,\n",
    "                            empty_drop_dataset=dataset_obj.get_count_matrix_empties(),\n",
    "                            random_state=dataset_obj.random,\n",
    "                            batch_size=batch_size,\n",
    "                            training_fraction=frac,\n",
    "                            fraction_empties=fraction_empties,\n",
    "                            shuffle=True,\n",
    "                            use_cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the optimizer.\n",
    "optimizer = pyro.optim.clipped_adam.ClippedAdam\n",
    "optimizer_args = {'lr': learning_rate, 'clip_norm': 10.}\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a learning rate scheduler.\n",
    "minibatches_per_epoch = int(np.ceil(len(train_loader) / train_loader.batch_size).item())\n",
    "scheduler_args = {'optimizer': optimizer,\n",
    "                    'max_lr': learning_rate * 10,\n",
    "                    'steps_per_epoch': minibatches_per_epoch,\n",
    "                    'epochs': epochs,\n",
    "                    'optim_args': optimizer_args}\n",
    "scheduler = pyro.optim.OneCycleLR(scheduler_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model.model_type == \"simple\":\n",
    "    loss_function = Trace_ELBO()\n",
    "else:\n",
    "    loss_function = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svi = SVI(model.model, model.guide, scheduler, loss=loss_function)\n",
    "svi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_elbo, test_elbo, succeeded = run_training(model, svi, train_loader, test_loader,\n",
    "                                                epochs=epochs, test_freq=5,\n",
    "                                                final_elbo_fail_fraction=None,\n",
    "                                                epoch_elbo_fail_fraction=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
